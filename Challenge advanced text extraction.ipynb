{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=[x for x in chosenlist]\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 10\n",
    "\n",
    "# Number of topics.\n",
    "ntopics= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categs =['rec.autos',\n",
    "         'sci.space',\n",
    "         'soc.religion.christian',\n",
    "         'talk.politics.mideast']\n",
    "news_raw = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'), categories = categs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame({'text':news_raw.data})\n",
    "\n",
    "# removing everything except alphabets`\n",
    "news['text_clean'] = news['text'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiya \\n\\nI'm a VERY amuture astronomer in Adel...</td>\n",
       "      <td>Hiya   I m a VERY amuture astronomer in Adelai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\tYou mean he talks about those Jews, who,...</td>\n",
       "      <td>You mean he talks about those Jews  who  be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: Center for Policy Research &lt;cpr&gt;\\nSubjec...</td>\n",
       "      <td>From  Center for Policy Research  cpr  Subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nFirst of all, \"ceremonial law\" is an extra...</td>\n",
       "      <td>First of all   ceremonial law  is an extraSc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nCarrying a pistol, loaded or unloaded, in th...</td>\n",
       "      <td>Carrying a pistol  loaded or unloaded  in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hiya \\n\\nI'm a VERY amuture astronomer in Adel...   \n",
       "1  \\n\\n\\tYou mean he talks about those Jews, who,...   \n",
       "2  From: Center for Policy Research <cpr>\\nSubjec...   \n",
       "3  \\n\\nFirst of all, \"ceremonial law\" is an extra...   \n",
       "4  \\nCarrying a pistol, loaded or unloaded, in th...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  Hiya   I m a VERY amuture astronomer in Adelai...  \n",
       "1     You mean he talks about those Jews  who  be...  \n",
       "2  From  Center for Policy Research  cpr  Subject...  \n",
       "3    First of all   ceremonial law  is an extraSc...  \n",
       "4   Carrying a pistol  loaded or unloaded  in the...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf matrix.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "news_tfidf=vectorizer.fit_transform(news['text_clean'])\n",
    "\n",
    "# Getting the word list.\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "news_lsa = lsa.fit_transform(news_tfidf)\n",
    "\n",
    "news_components_lsa = word_topic(news_tfidf, news_lsa, vocabulary)\n",
    "\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "topwords['LSA']=top_words(news_components_lsa, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "news_nmf = nmf.fit_transform(news_tfidf) \n",
    "\n",
    "news_components_nmf = word_topic(news_tfidf, news_nmf, vocabulary)\n",
    "\n",
    "topwords['NNMF']=top_words(news_components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "            LSA          LDA         NNMF\n",
      "0     god 30.62    just 1.45     car 2.96\n",
      "0  people 29.67  people 1.23    like 1.22\n",
      "0    just 28.65    like 1.22    just 1.19\n",
      "0     like 26.9     car 1.18     don 0.95\n",
      "0   think 24.64     god 1.13    cars 0.94\n",
      "0     don 24.56    think 1.1    know 0.93\n",
      "0    know 24.39     know 1.1    good 0.88\n",
      "0    does 20.15   space 1.08   think 0.81\n",
      "0    time 18.94   loser 1.06     new 0.73\n",
      "0     say 17.78     don 1.04  engine 0.71\n",
      "Topic 1:\n",
      "               LSA          LDA             NNMF\n",
      "1        god 24.27    like 1.41         god 5.51\n",
      "1      jesus 11.67    just 1.41       jesus 2.64\n",
      "1       faith 7.23     don 1.18       people 2.0\n",
      "1       church 6.9     car 1.18     believe 1.69\n",
      "1       bible 6.68    know 1.13       faith 1.59\n",
      "1      christ 6.53     god 1.04       bible 1.53\n",
      "1      believe 6.1  people 1.03      christ 1.48\n",
      "1  christians 5.98    good 1.01       think 1.47\n",
      "1         hell 5.1     does 1.0  christians 1.42\n",
      "1   christian 4.89    time 0.94      church 1.41\n",
      "Topic 2:\n",
      "              LSA           LDA            NNMF\n",
      "2    israel 11.52     god 36.27   armenian 3.14\n",
      "2       jews 7.66  people 33.54  armenians 2.49\n",
      "2    israeli 7.14    just 30.89    turkish 2.26\n",
      "2   armenian 6.45    like 30.57      people 1.5\n",
      "2    turkish 5.65     car 27.47   genocide 1.29\n",
      "2  armenians 5.54   think 27.03    armenia 1.22\n",
      "2        arab 4.6      don 26.8      turks 1.15\n",
      "2     jewish 4.09    know 26.69     turkey 1.14\n",
      "2      arabs 3.44   space 25.47     soviet 0.95\n",
      "2        war 3.28  israel 22.22       said 0.91\n",
      "Topic 3:\n",
      "              LSA            LDA           NNMF\n",
      "3    armenian 8.6  retarded 1.43    israel 4.32\n",
      "3  armenians 7.42      just 1.37    israeli 2.4\n",
      "3    turkish 6.91      like 1.26      jews 1.85\n",
      "3     turkey 3.85        car 1.2      arab 1.56\n",
      "3    armenia 3.82    people 1.12     arabs 1.13\n",
      "3      turks 3.58      does 1.12  lebanese 1.01\n",
      "3   genocide 3.47      know 1.11   lebanon 0.92\n",
      "3     serdar 3.02       god 1.08    people 0.89\n",
      "3        god 2.85       don 1.08     peace 0.88\n",
      "3       greek 2.8     think 1.03      adam 0.87\n",
      "Topic 4:\n",
      "            LSA          LDA          NNMF\n",
      "4   space 16.61    just 1.62    space 4.82\n",
      "4     nasa 7.36    like 1.34     nasa 2.15\n",
      "4  shuttle 4.29     know 1.2  shuttle 1.27\n",
      "4    orbit 4.26     car 1.14   launch 1.26\n",
      "4    launch 4.1     edu 1.12    orbit 1.03\n",
      "4    earth 3.63      god 1.1     moon 1.01\n",
      "4     moon 3.57  people 1.09    lunar 0.95\n",
      "4    lunar 3.41     don 1.01  program 0.94\n",
      "4  program 3.22   think 1.01     earth 0.9\n",
      "4     data 3.12   space 0.92     data 0.88\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSA Model** was able to reproduce 3 topics out of the 4 topics represented by newsgroups and included in this model. (The topics are 'sci.space' (Topic 4),'soc.religion.christian' (Topics 0 & 1),'talk.politics.mideast' (Topics 2 & 3) <br>\n",
    "**LDA Model** was not able to reproduce any of the topics reprsented by newsgroups. All the topics has words from more than one topic.<br>\n",
    "**NNMF Model** was able to reproduce 4 topics out of the 4 topics represented by newsgroups and included in this model. (The topics are 'sci.space' (Topic 4),'soc.religion.christian' (Topic 1),'talk.politics.mideast' (Topics 2 & 3), 'rec.autos' (Topic 0)  <br>\n",
    "\n",
    "Therefore, The best model is NNMF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
